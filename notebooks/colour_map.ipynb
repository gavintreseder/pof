{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Notebook for developing the colour map & axis lock logic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pof import Component, FailureMode\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pof.data.asset_data import SimpleFleet\n",
    "import copy\n",
    "from pof.loader.asset_model_loader import AssetModelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pof.paths import Paths\n",
    "\n",
    "# Forecast years\n",
    "START_YEAR = 2015\n",
    "END_YEAR = 2024\n",
    "CURRENT_YEAR = 2020\n",
    "\n",
    "paths = Paths()\n",
    "\n",
    "# Population Data\n",
    "file_path = paths.input_path + os.sep\n",
    "FILE_NAME = r\"population_summary.csv\"\n",
    "\n",
    "sfd = SimpleFleet(file_path + FILE_NAME)\n",
    "sfd.load()\n",
    "sfd.calc_age_forecast(START_YEAR, END_YEAR, CURRENT_YEAR);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:04<00:00, 24.24it/s]\n",
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:03<00:00, 27.93it/s]\n",
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:03<00:00, 31.21it/s]\n",
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:02<00:00, 38.35it/s]\n",
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:04<00:00, 23.81it/s]\n",
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:04<00:00, 24.33it/s]\n",
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:03<00:00, 29.86it/s]\n",
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:02<00:00, 35.03it/s]\n",
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:03<00:00, 29.15it/s]\n",
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:02<00:00, 35.43it/s]\n",
      "WARNING:root:Update Failed. {error}\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.07it/s]\n"
     ]
    }
   ],
   "source": [
    "comp = Component.demo()\n",
    "df = comp.expected_sensitivity(\n",
    "        var_id=\"pole-fm-termites-dists-untreated-alpha\", lower=0, upper=10, step_size=1, n_iterations=100, t_end=100\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_order(df, column):\n",
    "    \"\"\"\n",
    "    sorts the dataframes for the graphs with total, risk and direct first\n",
    "    \"\"\"\n",
    "    if column is None:\n",
    "        raise ValueError(\"Column must be defined\")\n",
    "\n",
    "    if column == \"task\":\n",
    "        values = df[\"task\"].unique().tolist()\n",
    "        values.sort()\n",
    "    elif column == \"source\":\n",
    "        values = df[\"source\"].unique().tolist()\n",
    "        values.sort()\n",
    "\n",
    "    start_order = [\"total\", \"inspection\", \"direct\"]\n",
    "    set_order = []\n",
    "\n",
    "    for var in start_order:\n",
    "        if var in values:\n",
    "            set_order.append(var)\n",
    "\n",
    "    for var in values:\n",
    "        if var not in set_order:\n",
    "            set_order.append(var)\n",
    "\n",
    "    return_order = {}\n",
    "    i = 1\n",
    "    for var in set_order:\n",
    "        return_order[var] = i\n",
    "        i = i + 1\n",
    "    # print(return_order)\n",
    "    df_ordered = df.sort_values(by=[column], key=lambda x: x.map(return_order))\n",
    "    # print(df_ordered.head())\n",
    "\n",
    "    return df_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_map(df, column):\n",
    "\n",
    "    df = df_order(df, column)\n",
    "\n",
    "    if column == \"source\":\n",
    "        colors = px.colors.qualitative.Plotly\n",
    "    elif column == \"task\":\n",
    "        colors = px.colors.qualitative.Bold\n",
    "    else:\n",
    "        colors = px.colors.qualitative.Safe\n",
    "\n",
    "    color_map = dict(zip(df[column].unique(), colors))\n",
    "\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_df = comp.expected_risk_cost_df(t_end=None)\n",
    "\n",
    "task_df.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_color_map(df=task_df, column=\"task\");"
   ]
  },
  {
   "source": [
    "#AXIS LOCK"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Invalid Data () - {'task': 'inspection', 'level_of_repair': 'as_bad_as_old', 'admin': 'yes', 'maint': 'no', 'travel': 'yes'}\n",
      "WARNING:root:Invalid Data () - {'task': 'repair', 'level_of_repair': 'grp'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "WARNING:root:Invalid Data () - {'task': 'inspection', 'admin': 'yes', 'maint': 'no', 'travel': 'yes'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "WARNING:root:Invalid Data () - {'task': 'inspection', 'level_of_repair': 'as_bad_as_old', 'admin': 'yes', 'maint': 'no', 'travel': 'yes'}\n",
      "WARNING:root:Invalid Data () - {'task': 'repair', 'level_of_repair': 'as_bad_as_old'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "WARNING:root:Invalid Data () - {'task': 'inspection', 'level_of_repair': 'as_bad_as_old'}\n",
      "WARNING:root:Invalid Data () - {'task': 'inspection', 'admin': 'yes', 'maint': 'no', 'travel': 'yes'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "WARNING:root:Invalid Data () - {'task': 'inspection', 'level_of_repair': 'as_bad_as_old'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "WARNING:root:Invalid Data () - {'task': 'inspection', 'level_of_repair': 'as_bad_as_old'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "WARNING:root:Invalid Data () - {'task': 'inspection'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "WARNING:root:Invalid Data () - {'task': 'replace', 'level_of_repair': 'as_good_as_new'}\n",
      "100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n"
     ]
    }
   ],
   "source": [
    "aml = AssetModelLoader(paths.demo_path + os.sep + \"Asset Model - Pole - Timber.xlsx\")\n",
    "comp_data = aml.load(paths.demo_path + os.sep + \"Asset Model - Pole - Timber.xlsx\")\n",
    "comp = Component.from_dict(comp_data[\"pole\"])\n",
    "comp.fleet_data = sfd\n",
    "\n",
    "t_end = 100\n",
    "\n",
    "pof_sim = copy.copy(comp)\n",
    "sens_sim = copy.deepcopy(comp)\n",
    "\n",
    "# Complete the simulations\n",
    "pof_sim.mp_timeline(t_end=t_end, n_iterations=1);\n",
    "\n",
    "# Produce reports\n",
    "pof_sim.expected_risk_cost_df(t_end=t_end);\n",
    "# pof_sim.calc_pof_df(t_end=t_end)\n",
    "pof_sim.calc_df_task_forecast(sfd.df_age_forecast);\n",
    "# pof_sim.calc_summary(sfd.df_age)\n",
    "pof_sim.calc_df_cond(t_end=t_end);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_max(chart, t_end=None, x_axis=None, y_axis=None, axis_lock=None):\n",
    "    \"\"\" Determine the maximum y value for a given axis \"\"\"\n",
    "\n",
    "    global pof_sim\n",
    "    global sens_sim\n",
    "\n",
    "    if \"pof\" in chart:\n",
    "        df = pof_sim.df_pof\n",
    "        x_col = None\n",
    "        y_col = \"pof\"\n",
    "    elif \"cond\" in chart:\n",
    "        df = pof_sim.df_cond\n",
    "        x_col = None\n",
    "        y_col = \"y\" + chart.split(\"_\")[-1]\n",
    "    elif \"ms\" in chart:\n",
    "        df = pof_sim.df_erc\n",
    "        x_col = \"time\"\n",
    "        y_col = y_axis\n",
    "    elif \"sens\" in chart:\n",
    "        df = sens_sim.df_sens\n",
    "        x_col = x_axis.split(\"-\")[-1]\n",
    "        y_col = y_axis\n",
    "    elif \"task\" in chart:\n",
    "        df = pof_sim.df_task\n",
    "        x_col = None\n",
    "        y_col = \"pop_quantity\"\n",
    "\n",
    "    try:\n",
    "        if axis_lock is None:\n",
    "            if x_col is not None:\n",
    "                y_max = df.groupby(x_col)[y_col].sum().max() * 1.05\n",
    "            else:\n",
    "                y_max = df[y_col].max() * 1.05\n",
    "        else:\n",
    "            ctx = dash.callback_context\n",
    "            dash_id = ctx.triggered[0][\"prop_id\"].split(\".\")[0]\n",
    "            if dash_id == \"sens_var_y-dropdown\" and x_col is not None:\n",
    "                y_max = df.groupby(x_col)[y_col].sum().max() * 1.05\n",
    "            else:\n",
    "                return dash.no_update\n",
    "    except:\n",
    "        y_max = None\n",
    "    return y_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max_values = []\n",
    "chart_list = [\n",
    "    # \"pof_fig\",\n",
    "    \"ms_fig\", \n",
    "    \"sens_fig\", \n",
    "    \"task_fig\"\n",
    "]\n",
    "\n",
    "for chart in chart_list:\n",
    "    y_max_values.append(get_y_max(chart=chart, t_end=200, x_axis=\"cost\", y_axis=\"cost\", axis_lock=False))\n",
    "\n",
    "y_max_values;"
   ]
  },
  {
   "source": [
    "Divide by 0 - inf error logic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from pof.indicator import Indicator\n",
    "from pof.component import Component\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "\n",
    "comp = Component.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 25.25it/s]\n"
     ]
    }
   ],
   "source": [
    "comp.mp_timeline(t_end=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _expected_condition(ec, conf):\n",
    "    \"\"\"\n",
    "    Returns the expected condition based\n",
    "    \"\"\"\n",
    "    # TODO make work for all condition levels loss:bool=False\n",
    "\n",
    "    mean = ec.mean(axis=0)\n",
    "    sigma = ec.std(axis=0)\n",
    "\n",
    "    # Create a dataframe with mean & sigma\n",
    "    df_mean_sigma = pd.DataFrame(\n",
    "        data={\"mean\": mean, \"sigma\": sigma},\n",
    "        columns=[\"mean\", \"sigma\"],\n",
    "    )\n",
    "\n",
    "    # Filter out rows when sigma = 0\n",
    "    # df_mean_sigma_filtered = df_mean_sigma[df_mean_sigma[\"sigma\"] != 0]\n",
    "    mean_filtered = df_mean_sigma[df_mean_sigma[\"sigma\"] != 0][\"mean\"]\n",
    "    sigma_filtered = df_mean_sigma[df_mean_sigma[\"sigma\"] != 0][\"sigma\"]\n",
    "\n",
    "    # TODO maybe add np.sqr(len(ec)) to make it stderr\n",
    "\n",
    "    # Calculate bounds\n",
    "    df_mean_sigma.loc[df_mean_sigma[\"sigma\"] != 0, \"upper\"] = ss.norm.ppf(\n",
    "        (1 - (1 - conf) / 2), loc=mean_filtered, scale=sigma_filtered\n",
    "    )\n",
    "    df_mean_sigma.loc[df_mean_sigma[\"sigma\"] != 0, \"lower\"] = ss.norm.ppf(\n",
    "        ((1 - conf) / 2), loc=mean_filtered, scale=sigma_filtered\n",
    "    )\n",
    "    df_mean_sigma.loc[df_mean_sigma[\"sigma\"] == 0, \"upper\"] = df_mean_sigma[\"mean\"]\n",
    "    df_mean_sigma.loc[df_mean_sigma[\"sigma\"] == 0, \"lower\"] = df_mean_sigma[\"mean\"]\n",
    "\n",
    "\n",
    "    # Adjust upper and lower to the mean if there is not variance (sigma was 0)\n",
    "    # print(df_mean_sigma)\n",
    "    # df_lower_upper = pd.merge(\n",
    "    #     df_mean_sigma, df_mean_sigma_filtered, how=\"left\", on=[\"mean\", \"sigma\"]\n",
    "    # )\n",
    "    # df_lower_upper[\"upper\"].fillna(df_lower_upper[\"mean\"])\n",
    "    # df_lower_upper[\"lower\"].fillna(df_lower_upper[\"mean\"])\n",
    "    upper = df_mean_sigma[\"upper\"]\n",
    "    lower = df_mean_sigma[\"lower\"]\n",
    "    print(df_mean_sigma)\n",
    "\n",
    "    # for i in range(0, len(upper)):\n",
    "        # if self.decreasing:\n",
    "        # if upper[i] > 100:\n",
    "        #     upper[i] = 100\n",
    "        # elif lower[i] < 0:\n",
    "        #     lower[i] = 0\n",
    "    upper[upper > 100] = 100\n",
    "    lower[lower < 0] = 0\n",
    "        # else:\n",
    "        #     upper[upper[i] > 0] = 0\n",
    "        #     lower[lower[i] < 100] = 100\n",
    "\n",
    "    expected = dict(\n",
    "        lower=lower,\n",
    "        mean=mean,\n",
    "        upper=upper,\n",
    "    )\n",
    "\n",
    "    return expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in comp.indicator.items():\n",
    "    ec = val.agg_timelines();\n",
    "\n",
    "# _expected_condition(ec, 0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}